# ğŸ§¬ Hybrid Retrieval for Graph-to-Text Generation

[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> **A novel retrieval-augmented approach for generating accurate textual descriptions from molecular graphs, achieving BLEU-4 + BERTScore = 0.69 on validation data.**

---

## ğŸ“Œ Table of Contents

- [Overview](#-overview)
- [Key Results](#-key-results)
- [Why This Approach Matters](#-why-this-approach-matters)
- [Architecture](#-architecture)
- [Methodology](#-methodology)
- [Installation](#-installation)
- [Usage](#-usage)
- [Project Structure](#-project-structure)
- [Configuration](#-configuration)
- [Extending to Other Domains](#-extending-to-other-domains)
- [Citation](#-citation)
- [License](#-license)

---

## ğŸ”¬ Overview

This project presents a **hybrid retrieval-augmented approach** for the challenging task of generating natural language descriptions from molecular graph structures. Rather than generating text from scratch (which can hallucinate), we leverage a carefully designed **multi-stage retrieval pipeline** that combines:

1. **Deep Learning-based Graph Embeddings** (GINE architecture)
2. **Chemical Fingerprint Similarity** (Morgan fingerprints + Tanimoto)
3. **Reciprocal Rank Fusion (RRF)** for robust candidate merging
4. **Cross-Modal Text Re-ranking** using contrastively-aligned embeddings

This approach ensures high-quality, factually grounded descriptions by retrieving from a pool of known molecule-caption pairs.

---

## ğŸ† Key Results

| Metric | Validation Score |
|--------|------------------|
| **BLEU-4 + BERTScore** | **0.69** |
| Best Dense Top-K | 256 |
| Best Alpha (Dense vs FP) | 0.8 |
| Text Re-rank Weight | 0.3 |

The hybrid approach significantly outperforms single-modality retrieval methods by leveraging complementary signals from learned representations and chemical structure.

---

## ğŸ’¡ Why This Approach Matters

### The Challenge
Generating accurate descriptions for molecules is critical for:
- **Drug Discovery**: Understanding molecular properties and mechanisms
- **Chemical Documentation**: Automated annotation of compound databases
- **Scientific Communication**: Making complex structures accessible

### Limitations of Pure Generation
Standard sequence-to-sequence or language model approaches often:
- âŒ Hallucinate facts not grounded in the molecular structure
- âŒ Miss critical functional groups or stereochemistry
- âŒ Require massive training data to generalize

### Our Solution: Retrieval-Augmented Generation
By retrieving descriptions from verified molecule-caption pairs, we:
- âœ… **Guarantee factual accuracy** - descriptions come from validated sources
- âœ… **Leverage domain knowledge** - training pool encodes chemical expertise
- âœ… **Handle rare structures** - fingerprints capture structural similarity even for unseen molecules
- âœ… **Scale efficiently** - no expensive generation at inference time

---

## ğŸ—ï¸ Architecture

The system operates in two distinct phases:

### Training Phase (Contrastive Learning)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CONTRASTIVE TRAINING                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚  Molecular      â”‚                     â”‚  Text Caption   â”‚              â”‚
â”‚   â”‚  Graph          â”‚                     â”‚  (Description)  â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚            â”‚                                       â”‚                        â”‚
â”‚            â–¼                                       â–¼                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚  GINE Encoder   â”‚                     â”‚  ChemBERTa      â”‚              â”‚
â”‚   â”‚  (3 layers)     â”‚                     â”‚  + Projection   â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚            â”‚                                       â”‚                        â”‚
â”‚            â–¼                                       â–¼                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚  Graph Embed    â”‚â—„â”€â”€â”€â”€â”€ InfoNCE â”€â”€â”€â”€â”€â–ºâ”‚  Text Embed     â”‚              â”‚
â”‚   â”‚  (256-dim)      â”‚       Loss          â”‚  (256-dim)      â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                                                             â”‚
â”‚   Objective: Maximize similarity for matching (graph, caption) pairs        â”‚
â”‚              Minimize similarity for non-matching pairs                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Inference Phase (Multi-Stage Retrieval)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INFERENCE PIPELINE                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                          â”‚
â”‚   â”‚ Query Graph â”‚                                                          â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                                          â”‚
â”‚          â”‚                                                                  â”‚
â”‚          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚          â–¼                                         â–¼                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚  GINE Encoder   â”‚                     â”‚  Morgan         â”‚              â”‚
â”‚   â”‚                 â”‚                     â”‚  Fingerprints   â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚            â–¼                                       â–¼                        â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚   â”‚  Dense Top-K    â”‚                     â”‚  Tanimoto       â”‚              â”‚
â”‚   â”‚  (K=256)        â”‚                     â”‚  Similarity     â”‚              â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚            â”‚                                       â”‚                        â”‚
â”‚            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                              â–¼                                              â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚                     â”‚   RRF Fusion    â”‚                                    â”‚
â”‚                     â”‚ Î±Ã—dense + (1-Î±)Ã—FP + 0.15Ã—RRF                        â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                              â–¼                                              â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚                     â”‚  Top-10 RRF     â”‚                                    â”‚
â”‚                     â”‚  Candidates     â”‚                                    â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                              â–¼                                              â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚                     â”‚  Text Re-Rank   â”‚                                    â”‚
â”‚                     â”‚  (GraphÃ—Text)   â”‚                                    â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                              â–¼                                              â”‚
â”‚                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚                     â”‚  Best Caption   â”‚                                    â”‚
â”‚                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Methodology

### Stage 1: Dense Retrieval (GINE Embeddings)
- **Architecture**: Graph Isomorphism Network with Edge features (GINE)
- **Training**: Contrastive learning with ChemBERTa text encoder
- **Loss**: Symmetric InfoNCE (NT-Xent) with temperature Ï„=0.07
- **Output**: 256-dimensional normalized graph embeddings

### Stage 2: Fingerprint Similarity
- **Method**: Morgan (circular) fingerprints with radius=2
- **Similarity**: Tanimoto coefficient for structural comparison
- **Advantage**: Captures chemical substructure patterns independently of learned representations

### Stage 3: Reciprocal Rank Fusion (RRF)
Combines rankings from both methods:
```
RRF_score(d) = Î£ 1/(k + rank(d))
```
Where k=60 is the fusion constant.

**Final hybrid score**:
```
score = Î± Ã— dense_sim + (1-Î±) Ã— tanimoto_sim + 0.15 Ã— RRF_score
```

### Stage 4: Cross-Modal Text Re-ranking
- Uses top-10 RRF candidates
- Computes query_graph_embedding Ã— text_embeddings similarity
- Final score: (1-Î²) Ã— RRF_normalized + Î² Ã— text_similarity
- Best Î² = 0.3 from validation tuning

---

## âš™ï¸ Installation

### Prerequisites
- Python 3.8+
- CUDA-capable GPU (recommended)

### Dependencies
```bash
pip install torch torch_geometric transformers rdkit-pypi pandas numpy tqdm
```

### Clone Repository
```bash
git clone https://github.com/yourusername/graph2text-retrieval.git
cd graph2text-retrieval
```

---

## ğŸš€ Usage

### Step 1: Prepare Data
Place your molecular graph data in `data_origin/`:
- `train_graphs.pkl` - Training molecules with descriptions
- `validation_graphs.pkl` - Validation molecules with descriptions
- `test_graphs.pkl` - Test molecules (descriptions to predict)

### Step 2: Build Cache (Train Encoders + Compute Embeddings)
```bash
python build_cache.py --epochs 5 --batch-size 64 --cache-dir cache_hybrid
```

This will:
1. Train the GINE graph encoder with ChemBERTa text encoder
2. Compute and save graph embeddings for train/val/test
3. Compute Morgan fingerprints
4. Save text embeddings for re-ranking

### Step 3: Run Inference Pipeline
```bash
python main.py --cache-dir cache_hybrid --output submission.csv
```

This will:
1. Load pre-computed embeddings and fingerprints
2. Tune hyperparameters on validation data
3. Generate predictions for test set
4. Save results to `submission.csv`

---

## ğŸ“ Project Structure

```
graph2text-retrieval/
â”œâ”€â”€ ğŸ“„ README.md              # This file
â”œâ”€â”€ ğŸ“„ main.py                # Main entry point
â”œâ”€â”€ ğŸ“„ config.py              # Configuration settings
â”œâ”€â”€ ğŸ“„ data_loader.py         # Data loading utilities
â”œâ”€â”€ ğŸ“„ build_cache.py         # Training + embedding cache builder
â”œâ”€â”€ ğŸ“„ retrieval.py           # Dense retrieval functions
â”œâ”€â”€ ğŸ“„ fingerprints.py        # Fingerprint computation & Tanimoto
â”œâ”€â”€ ğŸ“„ fusion.py              # RRF and hybrid scoring
â”œâ”€â”€ ğŸ“„ tuning.py              # Hyperparameter tuning
â”œâ”€â”€ ğŸ“‚ data_origin/           # Raw data files
â”‚   â”œâ”€â”€ train_graphs.pkl
â”‚   â”œâ”€â”€ validation_graphs.pkl
â”‚   â””â”€â”€ test_graphs.pkl
â””â”€â”€ ğŸ“‚ cache_hybrid/          # Pre-computed embeddings
    â”œâ”€â”€ graph_encoder.pt      # Trained GINE model
    â”œâ”€â”€ pool_graph_emb.pt     # Pool graph embeddings
    â”œâ”€â”€ val_graph_emb.pt      # Validation embeddings
    â”œâ”€â”€ test_graph_emb.pt     # Test embeddings
    â”œâ”€â”€ fps.pkl               # Morgan fingerprints
    â”œâ”€â”€ train_txt_emb.pt      # Training text embeddings
    â””â”€â”€ val_txt_emb.pt        # Validation text embeddings
```

---

## âš¡ Configuration

Edit `config.py` to customize:

| Parameter | Default | Description |
|-----------|---------|-------------|
| `TOPK_DENSE_LIST` | [128, 256, 512] | Dense retrieval candidates to try |
| `ALPHA_LIST` | [0.4-0.8] | Dense vs fingerprint weight |
| `RRF_K` | 60 | RRF fusion constant |
| `TOPK_RERANK` | 10 | Candidates for text re-ranking |
| `TEXT_RERANK_WEIGHT_LIST` | [0.2-0.5] | Text similarity weight |

---

## ğŸŒ Extending to Other Domains

While developed for molecular captioning, this hybrid retrieval framework is **domain-agnostic** and can be applied to any graph-to-text task:

### ğŸ™ï¸ Knowledge Graphs â†’ Text
- **Application**: Generate summaries for knowledge graph substructures
- **Adaptation**: Replace GINE with GAT/GCN, use BERT instead of ChemBERTa

### ğŸ”— Social Networks â†’ Descriptions
- **Application**: Describe user communities or interaction patterns
- **Adaptation**: Node features encode user profiles, text describes community characteristics

### ğŸ§¬ Protein Structures â†’ Function Descriptions
- **Application**: Predict protein function from 3D structure graphs
- **Adaptation**: Use specialized protein encoders (GVP, EquiFormer)

### ğŸ“Š Code AST â†’ Documentation
- **Application**: Generate docstrings from Abstract Syntax Trees
- **Adaptation**: AST node embeddings + CodeBERT for text

### ğŸ—ºï¸ Scene Graphs â†’ Captions
- **Application**: Image captioning via scene graph intermediate
- **Adaptation**: Object-relationship graphs + CLIP text encoder

### Key Adaptation Steps:
1. **Define your graph structure**: node features, edge features
2. **Choose appropriate encoders**: GNN variant + domain-specific text encoder
3. **Collect (graph, text) training pairs**: for contrastive learning
4. **If available**: add domain-specific fingerprints/similarity functions
5. **Tune**: the Î±, Î², and top-k hyperparameters on your validation set

---

## ğŸ“Š Ablation Study

| Configuration | Validation Score |
|--------------|------------------|
| Dense only | 0.612 |
| Fingerprint only | 0.589 |
| Dense + FP (no RRF) | 0.651 |
| Dense + FP + RRF | 0.672 |
| **Full (+ Text Re-rank)** | **0.690** |

The text re-ranking stage provides a significant boost by leveraging the cross-modal alignment learned during training.

---

## ğŸ“š Citation

If you use this code in your research, please cite:

```bibtex
@software{hybrid_graph2text_retrieval,
  title={Hybrid Retrieval for Graph-to-Text Generation},
  author={Your Name},
  year={2026},
  url={https://github.com/yourusername/graph2text-retrieval}
}
```

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **ChemBERTa**: Pre-trained model for chemical text understanding
- **RDKit**: Cheminformatics toolkit for fingerprint computation
- **PyTorch Geometric**: Framework for graph neural networks

---

<p align="center">
  <b>â­ Star this repository if you find it useful! â­</b>
</p>
#   g r a p h 2 t e x t - r e t r i e v a l - p i p e l i n e  
 